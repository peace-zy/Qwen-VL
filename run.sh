/aistudio/workspace/qwen_train/env/pytorch_2.1.0_cu12.1_py3.11_qwen_vl/bin/python -u finetune.py --model_name_or_path /aistudio/workspace/qwen_train/models/Qwen/Qwen-VL-Chat --data_path /mnt/aigc_chubao/zhangyan461/dataset/vlm/visual_instruction_tuning/llava_instruct/LLaVA-Instruct-150K/qwen_format_llava_v1_5_mix665k.json --bf16 False --fix_vit True --output_dir output_qwen --num_train_epochs 5 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 16 --evaluation_strategy no --save_strategy steps --save_steps 1000 --save_total_limit 10 --learning_rate 1e-5 --weight_decay 0.1 --adam_beta2 0.95 --warmup_ratio 0.01 --lr_scheduler_type cosine --logging_steps 1 --report_to none --model_max_length 2048 --gradient_checkpointing True --lazy_preprocess True --deepspeed finetune/ds_config_zero2.json
